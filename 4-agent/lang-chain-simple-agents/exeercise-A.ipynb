{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9aa11912",
   "metadata": {},
   "source": [
    "## Simple LangChainAgent Exercise\n",
    "\n",
    "\n",
    "\n",
    "### Phase 1: Setup and Configuration\n",
    "- Before you begin, you need to initialize your environment and the connection to OpenAI.\n",
    "- ChatOpenAI: This is the primary class you will use. \n",
    "- In version 1.0+, ensure you are importing this from the langchain_openai partner package rather than the community or core packages.\n",
    "- os.environ: Use this to securely manage your OPENAI_API_KEY.\n",
    "\n",
    "### Phase 2: Defining the Prompt Architecture\n",
    "- Instead of sending raw strings, v1.0+ encourages structured message objects.\n",
    "- [ChatPromptTemplate](https://reference.langchain.com/python/langchain_core/prompts/#langchain_core.prompts.chat.ChatPromptTemplate): Use this to define the structure of your conversation.\n",
    "- [from_messages](https://reference.langchain.com/python/langchain_core/prompts/#langchain_core.prompts.chat.ChatPromptTemplate): A specific method within the prompt template class that allows you to define a list containing a [SystemMessage](https://reference.langchain.com/python/langchain_core/messages/#langchain_core.messages.SystemMessage) (to set the AI's behavior) and a [HumanMessage](https://reference.langchain.com/python/langchain_core/messages/#langchain_core.messages.HumanMessage) (the user's input).\n",
    "- [format_messages](https://reference.langchain.com/python/langchain_core/prompts/?h=format_messages#langchain_core.prompts.chat.ChatPromptTemplate.format_messages): The function you will call to inject your specific variables (like a topic or a task) into the template before sending it to the model.\n",
    "\n",
    "### Phase 3: Execution via the Runnable Interface\n",
    "- invoke: This is the \"gold standard\" function. You will call this directly on your model object. It takes the formatted messages as input and returns a complete response object.\n",
    "- content: Once the model returns a result, use this attribute on the response object to extract the actual text string.\n",
    "\n",
    "### The Exercise Flow\n",
    "- Initialize ChatOpenAI with your desired parameters (model name, temperature).\n",
    "- Create a ChatPromptTemplate using from_messages.\n",
    "- Prepare your data by calling format_messages on your template.\n",
    "- Pass that formatted output into the model's invoke function.\n",
    "- Print the content of the resulting object."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
