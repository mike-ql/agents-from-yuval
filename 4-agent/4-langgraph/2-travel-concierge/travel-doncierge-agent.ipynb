{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b348a59",
   "metadata": {},
   "source": [
    "#### The Travel Concierge\n",
    "- Here's an agent that helps you book a trip.\n",
    "- The agent's logic is:\n",
    "  - Look at the message history.\n",
    "  - Check which \"slots\" (Destination, Date, Class) are still missing.\n",
    "  - If something is missing, ask for it.\n",
    "  - If everything is present, \"book\" the trip.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4446e55d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Annotated, Optional\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "from dotenv import load_dotenv   # from the python-dotenv library - load the OpenAI API key from file\n",
    "load_dotenv(dotenv_path='../../../.env', override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e464269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome! I need your destination, date, and class.\n",
      "Assistant: I have noted N.Y. Can you tell me the date of travel?\n",
      "Assistant: I have noted December 24. What class would you like to travel in?\n",
      "Assistant: I have noted First class. Your travel to N.Y is on December 24 in First class.\n",
      "\n",
      "--- SYSTEM MESSAGE: All slots filled! Process complete. ---\n"
     ]
    }
   ],
   "source": [
    "from typing import Annotated, Optional\n",
    "from typing_extensions import TypedDict\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "# 1. We add specific fields to our State\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    # These fields stay None until the agent finds them in conversation\n",
    "    destination: Optional[str]\n",
    "    travel_date: Optional[str]\n",
    "    travel_class: Optional[str]\n",
    "\n",
    "class BookingInfo(BaseModel):\n",
    "    destination: Optional[str] = Field(None, description=\"The city the user wants to visit\")\n",
    "    travel_date: Optional[str] = Field(None, description=\"The day or date of travel\")\n",
    "    travel_class: Optional[str] = Field(None, description=\"Economy, Business, or First class\")\n",
    "    assistant_message: str = Field(..., description=\"The message to speak back to the user\")\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\").with_structured_output(BookingInfo)\n",
    "\n",
    "def concierge_node(state: State):\n",
    "    # Instructions to the LLM to act as a 'Slot Filler'\n",
    "    system_prompt = (\n",
    "        \"You are a travel assistant. Current Data:\\n\"\n",
    "        f\"Destination: {state.get('destination')}\\n\"\n",
    "        f\"Date: {state.get('travel_date')}\\n\"\n",
    "        f\"Class: {state.get('travel_class')}\\n\"\n",
    "        \"If data is missing, ask the user. If you just received data, \"\n",
    "        \"reply with 'I have noted [data].' and ask for the next item.\"\n",
    "    )\n",
    "    \n",
    "    messages = [(\"system\", system_prompt)] + state[\"messages\"]\n",
    "    response = llm.invoke(messages)\n",
    "    \n",
    "    # --- HERE IS THE KEY: LOGIC TO UPDATE THE STATE FIELDS ---\n",
    "    # In a real app, you'd use 'Tool Calling' for this. \n",
    "    # For this simple example, we'll just check if the user's last message \n",
    "    # contained certain keywords to update the state.\n",
    "    \n",
    "    return {\n",
    "        \"messages\": [(\"assistant\", response.assistant_message)],\n",
    "        \"destination\": response.destination or state.get(\"destination\"),\n",
    "        \"travel_date\": response.travel_date or state.get(\"travel_date\"),\n",
    "        \"travel_class\": response.travel_class or state.get(\"travel_class\")\n",
    "    }\n",
    "\n",
    "   \n",
    "\n",
    "# 2. Build the Graph\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"concierge\", concierge_node)\n",
    "builder.add_edge(START, \"concierge\")\n",
    "builder.add_edge(\"concierge\", END)\n",
    "\n",
    "memory = MemorySaver()\n",
    "app = builder.compile(checkpointer=memory)\n",
    "\n",
    "# 3. THE CLI LOOP (Now it checks the slots!)\n",
    "config = {\"configurable\": {\"thread_id\": \"user_789\"}}\n",
    "\n",
    "print(\"Welcome! I need your destination, date, and class.\")\n",
    "\n",
    "while True:\n",
    "    u_input = input(\"User: \")\n",
    "    if u_input.lower() in [\"quit\", \"exit\"]: break\n",
    "\n",
    "    # Run the agent\n",
    "    result = app.invoke({\"messages\": [(\"user\", u_input)]}, config)\n",
    "    \n",
    "    print(f\"Assistant: {result['messages'][-1].content}\")\n",
    "\n",
    "    # NOW THE CODE CHECKS THE STATE\n",
    "    is_destination_filled = result.get(\"destination\")\n",
    "    is_date_filled = result.get(\"travel_date\")\n",
    "    is_class_filled = result.get(\"travel_class\")\n",
    "\n",
    "    if is_destination_filled and is_date_filled and is_class_filled:\n",
    "        print(\"\\n--- SYSTEM MESSAGE: All slots filled! Process complete. ---\")\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
